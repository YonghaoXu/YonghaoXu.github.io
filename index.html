<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="icon" href="./images/icon.png">
<link rel="stylesheet" href="main.css" type="text/css" />
<link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
<!--- <title></title> --->
<title>Yonghao Xu's Homepage</title>
</head>
<body>
<div id="main-container">
<div id="header-container">
<div id="header">
<div id="header-icon-text-container">
<div id="header-icon-container" >
<a href="index.html"><img src="./images/icon.png" alt="" style="width: 100%; height: 100%; position: center; padding:0px; margin: 0px;"></a>
</div>
<div id="header-text-container">
<a href="index.html">Yonghao Xu üõ∞Ô∏è</a>
</div>
</div>
</div>
</div>
<div id="layout-content"> <!-- nomenu  -->
<div id="text-img-container"><div id="img-container">
<img src="./images/Yonghao.jpg" alt="" height="220px" /></div>
<div id="text-container"><h2><strong>Yonghao Xu</strong> <br />
  <br /></h2>
<h3>Post-doctoral Researcher<br /></h3>
<h3><a href="https://www.iarai.ac.at/" target=&ldquo;blank&rdquo;>Institute of Advanced Research in Artificial Intelligence</a><br /></h3>
<h3>E-mail: <tt>yonghaoxu@ieee.org</tt>; <tt>yonghao.xu@iarai.ac.at</tt><br /><br /></h3>
<p><a href="https://github.com/YonghaoXu" target=&ldquo;blank&rdquo;>[<tt>GitHub</tt>]</a> <a href="https://www.linkedin.com/in/yonghao-xu-4416b013b/" target=&ldquo;blank&rdquo;>[<tt>Linkedin</tt>]</a> <a href="https://dblp.uni-trier.de/pid/210/5089.html" target=&ldquo;blank&rdquo;>[<tt>dblp</tt>]</a> <a href="https://scholar.google.com/citations?user=sQs2ztAAAAAJ&amp;hl=en" target=&ldquo;blank&rdquo;>[<tt>Google Scholar</tt>]</a> <br />
</p>
</div></div>
<h2>Short Biography</h2>
<p>I am currently a post-doctoral researcher at the <a href="https://www.iarai.ac.at/" target=&ldquo;blank&rdquo;>Institute of Advanced Research in Artificial Intelligence (IARAI)</a> in Austria, working on <a href="https://www.ai4rs.com/">AI4RS</a> with <a href="https://www.pedram-ghamisi.com/" target=&ldquo;blank&rdquo;>Prof. Pedram Ghamisi</a>. Before that, I received the Ph.D. degree in Photogrammetry and Remote Sensing from Wuhan University, advised by <a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html" target=&ldquo;blank&rdquo;>Prof. Liangpei Zhang</a> and <a href="http://sigma.whu.edu.cn/" target=&ldquo;blank&rdquo;>Prof. Bo Du</a>.</p>
<h2>News</h2>
<ul>
<li><p> <strong>2022/10/01</strong> Call for Paper: <a href="https://www.frontiersin.org/research-topics/47246/remote-sensing-for-ecosystem-studies" target=&ldquo;blank&rdquo;> Special Issue of "Remote Sensing for Ecosystem Studies"</a> on Frontiers in Remote Sensing. </p>
</li>
<li><p> <strong>2022/08/01 </strong> Multiple Ph.D. and Postdoc Positions are available in AI4RS group at IARAI, Austria, and in Machine Learning Group at HZDR, Germany. See <a href="https://www.ai4rs.com/work-with-us">here</a> for details.</p>
</li>
<li><p> <strong>2022/04/01</strong> The Landslide4Sense 2022 competition opens! <a href="https://www.iarai.ac.at/landslide4sense/" target=&ldquo;blank&rdquo;>Landslide4Sense 2022</a> focuses on innovative algorithms for landslide detection using multi-sensor satellite data. See our <a href="https://github.com/iarai/Landslide4Sense-2022" target=&ldquo;blank&rdquo;>GitHub page</a> for the baseline code. </p>
</li>
<li><p> <strong>2022/04/01</strong> Call for Paper: <a href="https://www.iarai.ac.at/cdceo22" target=&ldquo;blank&rdquo;> 2nd workshop on Complex Data Challenges in Earth Observation (CDCEO)</a> in IJCAI-ECAI 2022. </p>
</li>
<li><p> <strong>2022/03/15</strong> Call for Paper: <a href="https://www.mdpi.com/journal/remotesensing/special_issues/adversarial_attacks" target=&ldquo;blank&rdquo;> Special Issue of "Adversarial Attacks and Defenses for Remote Sensing Data"</a> on MDPI-Remote Sensing. </p>
</li>
</ul>
<h2>Research Interests and Selected Publications</h2>
<ul>
<li><p><h3><b>Remote Sensing Image Synthesis from Text</b></h3></p>
</li>
<div id="text-img-container"><div id="img-container"><img src="./images/Txt2Img-MHN.png" alt="" width="180px" /></div>
<div id="text-container"><p><b>Y. Xu</b>, W. Yu, P. Ghamisi, M. Kopp, and S. Hochreiter, &ldquo;<a href="https://arxiv.org/abs/2208.04441" target=&rdquo;blank&ldquo;>Txt2Img-MHN: Remote sensing image generation from text using modern hopfield networks</a>,&rdquo; <i>arXiv preprint arXiv:2208.04441</i>, 2022.<br />
<a href="https://arxiv.org/abs/2208.04441" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a> <a href="https://github.com/yonghaoxu/txt2img-mhn" target=&ldquo;blank&rdquo;>[<tt>Code</tt>]</a> <a href="https://www.youtube.com/watch?v=oSuC6Z_xTK0&t=20s" target=&ldquo;blank&rdquo;>[<tt>Video</tt>]</a></p>
</div></div>
<li><p><h3><b>AI Security for Earth Observation</b></h3></p>
<div id="text-img-container"><div id="img-container">
<img src="./images/UAERS.png" alt="" width="180px" /></div>
<div id="text-container"><p><b>Y. Xu</b> and P. Ghamisi, &ldquo;<a href="https://ieeexplore.ieee.org/document/9726211/" target=&rdquo;blank&ldquo;>Universal adversarial examples in remote sensing: Methodology and benchmark</a>,&rdquo; <i>IEEE Trans. Geosci. Remote Sens.</i>, vol. 60, pp. 1‚àí15, 2022.<br />
<a href="https://arxiv.org/abs/2202.07054" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a> <a href="https://drive.google.com/file/d/1tbRSDJwhpk-uMYk2t-RUgC07x2wyUxAL/view?usp=sharing" target=&ldquo;blank&rdquo;>[<tt>Data</tt>]</a> <a href="https://github.com/YonghaoXu/UAE-RS" target=&ldquo;blank&rdquo;>[<tt>Code</tt>]</a> <a href="https://www.youtube.com/watch?v=-_7YZDH8guo&t=474s" target=&ldquo;blank&rdquo;>[<tt>Video</tt>]</a></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="./images/SACNet.png" alt="" width="180px" /></div>
<div id="text-container"><p><b>Y. Xu</b>, B. Du, and L. Zhang, &ldquo;<a href="https://ieeexplore.ieee.org/document/9573256/" target=&rdquo;blank&ldquo;>Self-attention context network: Addressing the threat of adversarial attacks for hyperspectral image classification</a>,&rdquo; <i>IEEE Trans. Image Process.</i>, vol. 30, pp. 8671-8685, 2021.<br />
<a href="https://ieeexplore.ieee.org/document/9573256/" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a> <a href="https://github.com/YonghaoXu/SACNet" target=&ldquo;blank&rdquo;>[<tt>Code</tt>]</a></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="./images/AdvRS.png" alt="" width="180px" /></div>
<div id="text-container"><p><b>Y. Xu</b>, B. Du, and L. Zhang, &ldquo;<a href="https://ieeexplore.ieee.org/abstract/document/9119167" target=&rdquo;blank&ldquo;>Assessing the threat of adversarial examples on deep neural networks for remote sensing scene classification: Attacks and defenses</a>,&rdquo; <i>IEEE Trans. Geosci. Remote Sens.</i>, vol. 59, no. 2, pp. 1604‚àí1617, 2021. (<tt><i><b>ESI Highly Cited Paper</b></i></tt>)<br />
<a href="https://ieeexplore.ieee.org/abstract/document/9119167/" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a></p>
</div></div>
<li><p><h3><b>Remote Sensing Image Interpretation</b></h3></p>
</li>
<div id="text-img-container"><div id="img-container">
<img src="./images/CRGNet.png" alt="" width="180px" /></div>
<div id="text-container"><p><b>Y. Xu</b> and P. Ghamisi, &ldquo;<a href="https://ieeexplore.ieee.org/document/9839390/" target=&rdquo;blank&ldquo;>Consistency-regularized region-growing network for semantic segmentation of urban scenes with point-level annotations</a>,&rdquo; <i>IEEE Trans. Image Process.</i>, vol. 31, pp. 5038‚Äì5051, 2022.<br />
<a href="https://arxiv.org/abs/2202.03740" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a> <a href="https://github.com/YonghaoXu/CRGNet" target=&ldquo;blank&rdquo;>[<tt>Code</tt>]</a> </p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="./images/RSEN.png" alt="" width="180px" /></div>
<div id="text-container"><p><b>Y. Xu</b>, B. Du, and L. Zhang, &ldquo;<a href="https://ieeexplore.ieee.org/abstract/document/9862940/" target=&rdquo;blank&ldquo;>Robust self-ensembling network for hyperspectral image classification</a>,&rdquo; <i>IEEE Trans. Neural Netw. Learn. Syst.</i>, doi: 10.1109/TNNLS.2022.3198142, 2022.<br />
<a href="https://arxiv.org/abs/2104.03765" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a> <a href="https://github.com/YonghaoXu/RSEN" target=&ldquo;blank&rdquo;>[<tt>Code</tt>]</a></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="./images/DFC18.png" alt="" width="180px" /></div>
<div id="text-container"><p><b>Y. Xu</b>, B. Du, L. Zhang, D. Cerra, M. Pato, E. Carmona, S. Prasad, N. Yokoya, R. Hansch, and B. Le Saux, &ldquo;<a href="https://ieeexplore.ieee.org/abstract/document/8727489" target=&rdquo;blank&ldquo;>Advanced multi-sensor optical remote sensing for urban land use and land cover classification: Outcome of the 2018 IEEE GRSS data fusion contest</a>,&rdquo; in <i>IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens.</i>, vol. 12, no. 6, pp. 1709‚àí1724, 2019. (<tt><i><b>ESI Highly Cited Paper</b></i></tt>)<br />
<a href="https://ieeexplore.ieee.org/abstract/document/8727489" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a> <a href="https://ieee-dataport.org/open-access/2018-ieee-grss-data-fusion-challenge-%E2%80%93-fusion-multispectral-lidar-and-hyperspectral-data" target=&ldquo;blank&rdquo;>[<tt>Data</tt>]</a></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="./images/RPNet.png" alt="" width="180px" /></div>
<div id="text-container"><p><b>Y. Xu</b>, B. Du, F. Zhang, and L. Zhang, &ldquo;<a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271618301473" target=&rdquo;blank&ldquo;>Hyperspectral image classification via a random patches network</a>,&rdquo; <i>ISPRS J. Photogram. Remote Sens.</i>, vol. 142, no. 10, pp. 344‚Äì357, 2018. (<tt><i><b>ESI Highly Cited Paper</b></i></tt>)<br />
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271618301473" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a> <a href="https://github.com/YonghaoXu/RPNet" target=&ldquo;blank&rdquo;>[<tt>Code</tt>]</a></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="./images/SSUN.png" alt="" width="180px" /></div>
<div id="text-container"><p><b>Y. Xu</b>, L. Zhang, B. Du, and F. Zhang, &ldquo;<a href="https://ieeexplore.ieee.org/document/8356713" target=&rdquo;blank&ldquo;>Spectral-spatial unified networks for hyperspectral image classification</a>,&rdquo; <i>IEEE Trans. Geosci. Remote Sens.</i>, vol. 56, no. 10, pp. 5893‚àí5909, 2018. (<tt><i><b>ESI Highly Cited Paper</b></i></tt>)<br />
<a href="https://ieeexplore.ieee.org/document/8356713" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a> <a href="https://github.com/YonghaoXu/SSUN" target=&ldquo;blank&rdquo;>[<tt>Code</tt>]</a></p>
</div></div>
<li><p><h3><b>Natural Hazard Monitoring</b></h3></p>
</li>
<div id="text-img-container"><div id="img-container">
<img src="./images/landslide4sense.png" alt="" width="180px" /></div>
<div id="text-container"><p>O. Ghorbanzadeh, <b>Y. Xu</b>, P. Ghamisi, M. Kopp, and D. Kreil, &ldquo;<a href="https://arxiv.org/abs/2206.00515" target=&rdquo;blank&ldquo;>Landslide4sense: Reference benchmark data and deep learning models for landslide detection</a>,&rdquo; <i> arXiv preprint arXiv:2206.00515</i>, 2022.<br />
<a href="https://arxiv.org/abs/2206.00515" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a> <a href="https://www.iarai.ac.at/landslide4sense/challenge/" target=&ldquo;blank&rdquo;>[<tt>Data</tt>]</a> <a href="https://github.com/iarai/Landslide4Sense-2022" target=&ldquo;blank&rdquo;>[<tt>Code</tt>]</a></p>
</div></div>
<li><p><h3><b>Cross-Domain Semantic Segmentation</b></h3></p>
</li>
<div id="text-img-container"><div id="img-container">
<img src="./images/APL.png" alt="" width="180px" /></div>
<div id="text-container"><p>L. Song, <b>Y. Xu</b>, L. Zhang, B. Du, Q. Zhang, and X. Wang, &ldquo;<a href="https://ieeexplore.ieee.org/abstract/document/9086819" target=&rdquo;blank&ldquo;>Learning from synthetic images via active pseudo-labeling</a>,&rdquo; <i>IEEE Trans. Image Process.</i>, vol. 29, pp. 6452-6465, 2020. <br />
<a href="https://ieeexplore.ieee.org/abstract/document/9086819" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a> <a href="https://github.com/lsongx/APL" target=&ldquo;blank&rdquo;>[<tt>Code</tt>]</a></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="./images/SEANet.png" alt="" width="180px" /></div>
<div id="text-container"><p><b>Y. Xu</b>, B. Du, L. Zhang, Q. Zhang, G. Wang, and L. Zhang, &ldquo;<a href="https://ojs.aaai.org//index.php/AAAI/article/view/4500" target=&rdquo;blank&ldquo;>Selfensembling attention networks: Addressing domain shift for semantic segmentation</a>,&rdquo; in <i>Proc. AAAI Conf. Artif. Intell.</i>, vol. 33, pp. 5581‚àí5588, 2019. <br />
<a href="https://ojs.aaai.org//index.php/AAAI/article/view/4500" target=&ldquo;blank&rdquo;>[<tt>Paper</tt>]</a> <a href="https://github.com/YonghaoXu/SEANet" target=&ldquo;blank&rdquo;>[<tt>Code</tt>]</a></p>
</div></div>
</ul>
<h2>Honors and Awards</h2>
<ul>
<li><p>Nominees award of Top 10 Academic Stars for graduate students at Wuhan University in 2019. </p>
</li>
<li><p>National Scholarship in 2015, 2018, and 2019. </p>
</li>
<li><p>1st Place in <a href="http://www.classic.grss-ieee.org/community/technical-committees/data-fusion/2018-ieee-grss-data-fusion-contest-results/" target=&ldquo;blank&rdquo;>2018 IEEE GRSS Data Fusion Contest</a>. </p>
</li>
</ul>
<h2>Academic Services and Activities</h2>
<ul>
<li><p>Co-lead of the WG-BEN in <a href="https://www.grss-ieee.org/technical-committees/image-analysis-and-data-fusion/" target=&ldquo;blank&rdquo;>IEEE GRSS Image Analysis and Data Fusion Technical Committee</a> (2022 &ndash; Now).</p>
</li>
<li>
  <p>Guest Editor of <a href="https://www.mdpi.com/journal/remotesensing/special_issues/adversarial_attacks/" target="‚Äúblank‚Äù">MDPI-Remote Sensing</a> (2022).</p>
</li>
<li>
  <p>Guest Editor of <a href="https://www.frontiersin.org/research-topics/47246/remote-sensing-for-ecosystem-studies" target="‚Äúblank‚Äù"> Frontiers in Remote Sensing</a> on Image Analysis and Classification (2022).</p>
</li>
<li>
  <p>Organizing Committee Member of <a href="https://www.iarai.ac.at/landslide4sense" target="‚Äúblank‚Äù"> Landslide4Sense 2022 Competition</a>.</p>
</li> 
<li>
  <p>Technical Committee Member of <a href="https://www.grss-ieee.org/events/earthvision-2022/" target="‚Äúblank‚Äù"> CVPR 2022 Workshop on EARTHVISION</a>.</p>
</li> 
<li>
  <p>Program Committee Member of <a href="https://www.iarai.ac.at/cdceo22/" target="‚Äúblank‚Äù"> IJCAI 2022 Workshop on CDCEO</a>.</p>
</li> 
<li>
  <p>Program Committee Member of <a href="https://www.iarai.ac.at/events/workshop-on-complex-data-challenges-in-earth-observation/" target="‚Äúblank‚Äù"> CIKM 2021 Workshop on CDCEO</a>.</p>
</li> 
<li><p>Chapter Chair of the IEEE GRSS Wuhan Student Branch (2017 &ndash; 2020). </p>
</li>
</ul>
<h2>Journal Reviewer</h2>
<ul>
<li><p>IEEE Transactions on Geoscience and Remote Sensing</p>
</li>
<li><p>IEEE Transactions Circuits and Systems for Video Technology</p>
</li>
<li><p>IEEE Transactions on Big Data</p>
</li>
<li><p>IEEE Journal of Selected Topics on Applied Remote Sensing</p>
</li>
<li><p>IEEE Geoscience and Remote Sensing Letters</p>
</li>
<li><p>ISPRS Journal of Photogrammetry and Remote Sensing</p>
</li>
<li><p>International Journal of Remote Sensing</p>
</li>
<li><p>Natural Resources Research</p>
</li>
<li><p>GIScience Remote Sensing</p>
</li>
<li><p>Pattern Recognition</p>
</li>
<li><p>Neural Networks</p>
</li>
</ul>
</div> <!-- <div id="layout-content"> -->
<div id="footer-container">
<div id="footer">
<div id="footer-text">
  <div align="center">Last updated on October 2022.</div>
</div> 
<!-- <div id="footer-text"> -->
</div> <!-- <div id="footer"> -->
</div> <!-- <div id="footer-container"> -->
<div> <!-- nomenulastbit to counteract  <div id="layout">  -->
</div> <!--- <div id="layout"> --->
</div> <!--- <div id="main-container"> --->

</body>
</html>
